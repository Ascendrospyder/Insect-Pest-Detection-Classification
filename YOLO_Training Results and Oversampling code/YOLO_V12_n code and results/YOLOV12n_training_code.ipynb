{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qC24ggK0mGn1",
        "outputId": "50cdebf0-8ea7-41af-c288-db40f9c90c64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.226-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.10.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.226-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.226 ultralytics-thop-2.0.18\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Collecting torch\n",
            "  Downloading torch-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.24.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Collecting torchaudio\n",
            "  Downloading torchaudio-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Collecting nvidia-nccl-cu12==2.27.5 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch)\n",
            "  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch)\n",
            "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.5.0 (from torch)\n",
            "  Downloading triton-3.5.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Downloading torch-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m147.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.5.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.24.0-cp312-cp312-manylinux_2_28_x86_64.whl (8.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m145.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m107.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.4.0\n",
            "    Uninstalling triton-3.4.0:\n",
            "      Successfully uninstalled triton-3.4.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nvshmem-cu12\n",
            "    Found existing installation: nvidia-nvshmem-cu12 3.4.5\n",
            "    Uninstalling nvidia-nvshmem-cu12-3.4.5:\n",
            "      Successfully uninstalled nvidia-nvshmem-cu12-3.4.5\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufile-cu12\n",
            "    Found existing installation: nvidia-cufile-cu12 1.11.1.6\n",
            "    Uninstalling nvidia-cufile-cu12-1.11.1.6:\n",
            "      Successfully uninstalled nvidia-cufile-cu12-1.11.1.6\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.8.0+cu126\n",
            "    Uninstalling torch-2.8.0+cu126:\n",
            "      Successfully uninstalled torch-2.8.0+cu126\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.23.0+cu126\n",
            "    Uninstalling torchvision-0.23.0+cu126:\n",
            "      Successfully uninstalled torchvision-0.23.0+cu126\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.8.0+cu126\n",
            "    Uninstalling torchaudio-2.8.0+cu126:\n",
            "      Successfully uninstalled torchaudio-2.8.0+cu126\n",
            "Successfully installed nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 torch-2.9.0 torchaudio-2.9.0 torchvision-0.24.0 triton-3.5.0\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.10.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.6\n"
          ]
        }
      ],
      "source": [
        "# installing the reqs\n",
        "!pip install ultralytics\n",
        "!pip install torch torchvision torchaudio --upgrade\n",
        "!pip install datasets evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# All imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from ultralytics import YOLO\n",
        "import os, time\n",
        "from datasets import load_from_disk\n",
        "import json\n",
        "import shutil\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "q2LMT_5sVz8i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef711c4c-7d14-45c2-a7b0-f99025a0c212"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYGGb-ryqo2Q",
        "outputId": "170f50e6-2f3f-4ca5-96dd-484575f1a7c9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "dataset = load_from_disk(\"/content/drive/MyDrive/COMP9517/hf_dataset\")\n",
        "print(dataset)\n",
        "### This is how the dataset looks like\n",
        "\n",
        "DatasetDict\n",
        "\n",
        "    train: Dataset({\n",
        "            features: ['image', 'objects'],\n",
        "            num_rows: 11502\n",
        "        })\n",
        "\n",
        "    validation: Dataset({\n",
        "        features: ['image', 'objects'],\n",
        "        num_rows: 1095\n",
        "    })\n",
        "\n",
        "    test: Dataset({\n",
        "        features: ['image', 'objects'],\n",
        "        num_rows: 546\n",
        "    })})"
      ],
      "metadata": {
        "id": "Q4d4_CKzrmMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO(\"/content/drive/MyDrive/COMP9517/yolo12n.pt\") # loading the model locally the version of ultralytics available on colab doesnt have yolov12\n",
        "\n",
        "# print(\"loaded yolo model:\", model)\n"
      ],
      "metadata": {
        "id": "YwG0DnrXmgiO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b01c8f2-6c05-4fc4-d7b6-e0eb1c22fdea"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo12n.pt to '/content/drive/MyDrive/COMP9517/yolo12n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.3MB 69.7MB/s 0.1s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First upload the kaggle_data.rar file to colab then run this code to load the data in the VM for faster training loading from drive takes a lot of time\n",
        "!apt-get install -y unrar\n",
        "!mkdir -p /content/dataset # not necessary still failsafe\n",
        "# extract the file\n",
        "!unrar x -y /content/kaggle_data.rar /content/dataset/\n",
        "# output cleared for now\n"
      ],
      "metadata": {
        "id": "wJVHvEJDgBZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Writing my own data.yaml with custom paths\n",
        "%%writefile data.yaml\n",
        "train: /content/dataset/kaggle_data/train/images\n",
        "val: /content/dataset/kaggle_data/valid/images\n",
        "test: /content/dataset/kaggle_data/test/images\n",
        "\n",
        "nc: 12\n",
        "\n",
        "names:\n",
        "  - Ants\n",
        "  - Bees\n",
        "  - Beetles\n",
        "  - Caterpillars\n",
        "  - Earthworms\n",
        "  - Earwigs\n",
        "  - Grasshoppers\n",
        "  - Moths\n",
        "  - Slugs\n",
        "  - Snails\n",
        "  - Wasps\n",
        "  - Weevils\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoH-pLDrOKiO",
        "outputId": "5efb5ea3-15ed-4205-9f2b-c1362bd1b86c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing data.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Pre-processing**\n",
        "\n",
        "All the images were already of the same size, ultralytics internally takes care of normalizing the pixel values, converting BGR to RGB and also applies some data augmentations by default such as random horizontal flip, HSV shifts, translation and most importantly mosaic\n",
        "\n",
        "### Mosaic\n",
        "The key idea is that before the images are placed into the four mosaic quadrants, each image is randomly scaled (resized) â€” sometimes bigger, sometimes smaller then cropped to fit into the mosaic.\n",
        "\n",
        "Mosaic automatically reduces later in training\n",
        "\n",
        "YOLO has a built in scheduler:\n",
        "\n",
        "1.   Early epochs: Mosaic = ON (strong augmentation)\n",
        "2.   As we go from MId to late epochs: Mosaic gradually reduces to near OFF\n",
        "3.   Last few epochs: No mosaic (model fine-tunes on real images)\n",
        "\n",
        "In summary,\n",
        "This helps the model avoid, overfitting early and unstable convergence late also we dont need to do this manually YOLO does it automatically"
      ],
      "metadata": {
        "id": "pScxZMkDpdhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train YOLOv12n with early stopping\n",
        "model.train(\n",
        "    data=\"data.yaml\",\n",
        "    epochs = 50,\n",
        "    imgsz = 640, # all the images are 640 * 640 for our data\n",
        "    batch =16,\n",
        "    project=\"my_yolo_experiment\", # store logs, plots, and weights at this dir /content/my_yolo_experiment/run_1/\n",
        "    name = \"run_1\",\n",
        "    exist_ok =True,\n",
        "    patience=5)\n",
        "# by default the best model will be saved when using early stopping"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nZUMJOZmkji",
        "outputId": "6822fb2b-f599-4daf-d421-2bfd9bbcad2d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.226 ğŸš€ Python-3.12.12 torch-2.9.0+cu128 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/drive/MyDrive/COMP9517/yolo12n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=run_1, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=5, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=my_yolo_experiment, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/my_yolo_experiment/run_1, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 16.2MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=12\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  2    180864  ultralytics.nn.modules.block.A2C2f           [128, 128, 2, True, 4]        \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  2    689408  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 1]        \n",
            "  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 11                  -1  1     86912  ultralytics.nn.modules.block.A2C2f           [384, 128, 1, False, -1]      \n",
            " 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 14                  -1  1     24000  ultralytics.nn.modules.block.A2C2f           [256, 64, 1, False, -1]       \n",
            " 15                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 17                  -1  1     74624  ultralytics.nn.modules.block.A2C2f           [192, 128, 1, False, -1]      \n",
            " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 20                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 21        [14, 17, 20]  1    433012  ultralytics.nn.modules.head.Detect           [12, [64, 128, 256]]          \n",
            "YOLOv12n summary: 272 layers, 2,570,388 parameters, 2,570,372 gradients, 6.5 GFLOPs\n",
            "\n",
            "Transferred 640/691 items from pretrained weights\n",
            "Freezing layer 'model.21.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 70.8MB/s 0.1s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1272.1Â±400.6 MB/s, size: 47.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/kaggle_data/train/labels... 11502 images, 3 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 11502/11502 1.5Kit/s 7.7s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/dataset/kaggle_data/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 674.8Â±285.0 MB/s, size: 34.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/kaggle_data/valid/labels... 1095 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1095/1095 1.1Kit/s 1.0s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/dataset/kaggle_data/valid/labels.cache\n",
            "Plotting labels to /content/my_yolo_experiment/run_1/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000625, momentum=0.9) with parameter groups 113 weight(decay=0.0), 120 weight(decay=0.0005), 119 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/my_yolo_experiment/run_1\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/50      3.33G      1.461      3.228      1.815         35        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 719/719 6.0it/s 1:60\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 35/35 3.4it/s 10.3s\n",
            "                   all       1095       1341      0.468      0.451      0.444      0.218\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/50      3.62G        1.5      2.492      1.813         42        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 719/719 7.4it/s 1:37\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 35/35 8.2it/s 4.3s\n",
            "                   all       1095       1341       0.51      0.495      0.485      0.224\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/50      3.63G      1.504      2.259      1.815         52        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 719/719 7.7it/s 1:33\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 35/35 8.4it/s 4.1s\n",
            "                   all       1095       1341      0.527      0.457      0.455      0.236\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/50      3.63G      1.491      2.107      1.801         33        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 719/719 7.8it/s 1:32\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 35/35 8.7it/s 4.0s\n",
            "                   all       1095       1341      0.626      0.568      0.583      0.322\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/50      3.63G      1.465      1.958      1.776         43        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 719/719 7.8it/s 1:32\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 35/35 8.8it/s 4.0s\n",
            "                   all       1095       1341      0.687      0.612       0.64      0.354\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/50      3.63G      1.441      1.862      1.757         34        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 719/719 7.9it/s 1:31\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 35/35 8.7it/s 4.0s\n",
            "                   all       1095       1341      0.709      0.612      0.661      0.375\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/50      3.63G      1.418      1.758       1.73         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 719/719 7.9it/s 1:31\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 35/35 8.5it/s 4.1s\n",
            "                   all       1095       1341      0.742      0.636      0.695       0.39\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/50      3.63G      1.397      1.696      1.715         49        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 719/719 7.9it/s 1:31\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 35/35 8.8it/s 4.0s\n",
            "                   all       1095       1341      0.748      0.643      0.697      0.399\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/50      3.63G      1.384      1.641      1.697         35        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 719/719 7.9it/s 1:31\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 35/35 8.9it/s 4.0s\n",
            "                   all       1095       1341      0.766      0.652        0.7      0.408\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/50      3.63G      1.364      1.579      1.689         48        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 719/719 7.9it/s 1:31\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 35/35 8.6it/s 4.1s\n",
            "                   all       1095       1341      0.828      0.653      0.718      0.407\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/50      3.63G      1.346      1.536      1.666         59        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 719/719 7.9it/s 1:31\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 35/35 8.8it/s 4.0s\n",
            "                   all       1095       1341      0.809      0.664       0.73      0.418\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/50      3.79G      1.348      1.495      1.672         49        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 719/719 7.8it/s 1:33\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 35/35 8.5it/s 4.1s\n",
            "                   all       1095       1341       0.81      0.668      0.731      0.425\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/50      3.79G      1.322      1.455      1.647         44        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 719/719 7.7it/s 1:33\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 35/35 8.6it/s 4.1s\n",
            "                   all       1095       1341      0.806      0.662      0.734      0.435\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/50      3.79G       1.32      1.417      1.644         38        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 719/719 7.7it/s 1:34\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 35/35 8.5it/s 4.1s\n",
            "                   all       1095       1341      0.757      0.711      0.747      0.437\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/50      3.79G      1.311      1.382      1.632         52        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 719/719 7.7it/s 1:33\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 35/35 8.6it/s 4.1s\n",
            "                   all       1095       1341      0.813      0.668      0.729       0.43\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/50      3.79G      1.296      1.362      1.626         51        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 719/719 7.8it/s 1:32\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 35/35 8.6it/s 4.1s\n",
            "                   all       1095       1341      0.802      0.719      0.762      0.452\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/50      3.79G      1.288      1.327      1.614         34        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 719/719 7.7it/s 1:33\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 35/35 8.5it/s 4.1s\n",
            "                   all       1095       1341      0.781      0.694      0.745      0.447\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/50      3.79G      1.278       1.31      1.605         42        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 719/719 7.8it/s 1:33\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 35/35 8.5it/s 4.1s\n",
            "                   all       1095       1341      0.808      0.713      0.766      0.455\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/50      3.79G      1.269      1.288      1.604         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 719/719 7.8it/s 1:32\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 35/35 8.8it/s 4.0s\n",
            "                   all       1095       1341      0.842      0.705       0.76      0.455\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/50      3.79G      1.265      1.257      1.596         27        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 719/719 7.8it/s 1:32\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 35/35 8.6it/s 4.1s\n",
            "                   all       1095       1341      0.823      0.695      0.754      0.455\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/50      3.79G      1.252      1.234      1.583         43        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 719/719 7.8it/s 1:33\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 35/35 8.7it/s 4.0s\n",
            "                   all       1095       1341      0.847      0.703      0.776      0.464\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/50      3.79G      1.242        1.2      1.574         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 719/719 7.8it/s 1:33\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 35/35 8.6it/s 4.1s\n",
            "                   all       1095       1341       0.83      0.711      0.764      0.468\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/50      3.79G      1.222      1.184      1.563         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 719/719 7.8it/s 1:32\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 35/35 8.1it/s 4.3s\n",
            "                   all       1095       1341       0.86      0.709      0.784      0.481\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/50      3.79G       1.22      1.165      1.558         32        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 719/719 7.8it/s 1:32\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 35/35 8.7it/s 4.0s\n",
            "                   all       1095       1341       0.87      0.706      0.781      0.474\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/50      3.79G      1.216      1.147      1.551         37        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 719/719 7.8it/s 1:32\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 35/35 8.5it/s 4.1s\n",
            "                   all       1095       1341      0.848      0.716      0.781      0.474\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      26/50      3.79G      1.203      1.125      1.542         51        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 719/719 7.7it/s 1:33\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 35/35 8.9it/s 3.9s\n",
            "                   all       1095       1341      0.829      0.726      0.782      0.481\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      27/50      3.79G        1.2      1.107      1.539         48        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 719/719 7.8it/s 1:32\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 35/35 8.7it/s 4.0s\n",
            "                   all       1095       1341      0.864      0.737      0.797      0.481\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      28/50      3.79G      1.192      1.086      1.532         30        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 719/719 7.7it/s 1:33\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 35/35 8.7it/s 4.0s\n",
            "                   all       1095       1341       0.86      0.731      0.789      0.476\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 5 epochs. Best results observed at epoch 23, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=5) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "28 epochs completed in 0.763 hours.\n",
            "Optimizer stripped from /content/my_yolo_experiment/run_1/weights/last.pt, 5.5MB\n",
            "Optimizer stripped from /content/my_yolo_experiment/run_1/weights/best.pt, 5.5MB\n",
            "\n",
            "Validating /content/my_yolo_experiment/run_1/weights/best.pt...\n",
            "Ultralytics 8.3.226 ğŸš€ Python-3.12.12 torch-2.9.0+cu128 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "YOLOv12n summary (fused): 159 layers, 2,559,068 parameters, 0 gradients, 6.3 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 35/35 7.0it/s 5.0s\n",
            "                   all       1095       1341      0.861      0.709      0.784      0.481\n",
            "                  Ants         96        178      0.842      0.663      0.722      0.291\n",
            "                  Bees         99        110      0.841        0.8      0.822      0.396\n",
            "               Beetles         89        100      0.684       0.55      0.637      0.307\n",
            "          Caterpillars         77        139       0.76      0.396      0.521      0.253\n",
            "            Earthworms         53         72      0.766      0.454      0.513      0.323\n",
            "               Earwigs         91        104      0.869      0.702      0.802      0.453\n",
            "          Grasshoppers         98        102      0.862      0.745      0.846      0.477\n",
            "                 Moths        100        101      0.951      0.911      0.958      0.761\n",
            "                 Slugs         77         91      0.878      0.516      0.715      0.445\n",
            "                Snails         99        107      0.957      0.953      0.987      0.719\n",
            "                 Wasps        116        132      0.965      0.856      0.918      0.641\n",
            "               Weevils        104        105      0.961      0.962      0.967      0.705\n",
            "Speed: 0.1ms preprocess, 0.8ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
            "Results saved to \u001b[1m/content/my_yolo_experiment/run_1\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
              "\n",
              "ap_class_index: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
              "box: ultralytics.utils.metrics.Metric object\n",
              "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7e7c380b2660>\n",
              "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
              "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.94737,     0.94737,     0.94737, ...,   0.0013651,  0.00068255,           0],\n",
              "       [          1,           1,           1, ...,   0.0026995,   0.0013498,           0],\n",
              "       [          1,           1,           1, ...,   0.0010932,  0.00054661,           0],\n",
              "       ...,\n",
              "       [          1,           1,           1, ...,    0.047703,    0.023852,           0],\n",
              "       [          1,           1,           1, ...,   0.0090401,     0.00452,           0],\n",
              "       [          1,           1,           1, ...,    0.024903,    0.012451,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.10136,     0.10136,      0.1353, ...,           0,           0,           0],\n",
              "       [    0.13648,     0.13648,     0.16829, ...,           0,           0,           0],\n",
              "       [   0.083409,    0.083409,     0.11983, ...,           0,           0,           0],\n",
              "       ...,\n",
              "       [    0.36364,     0.36364,     0.47907, ...,           0,           0,           0],\n",
              "       [    0.18575,     0.18575,     0.28715, ...,           0,           0,           0],\n",
              "       [    0.52041,     0.52041,     0.66062, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.05363,     0.05363,    0.073156, ...,           1,           1,           1],\n",
              "       [    0.07355,     0.07355,    0.092452, ...,           1,           1,           1],\n",
              "       [   0.043685,    0.043685,     0.06419, ...,           1,           1,           1],\n",
              "       ...,\n",
              "       [    0.22269,     0.22269,     0.31592, ...,           1,           1,           1],\n",
              "       [    0.10263,     0.10263,     0.16876, ...,           1,           1,           1],\n",
              "       [     0.3554,      0.3554,     0.50049, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.92135,     0.92135,     0.89888, ...,           0,           0,           0],\n",
              "       [    0.94545,     0.94545,     0.93636, ...,           0,           0,           0],\n",
              "       [       0.92,        0.92,         0.9, ...,           0,           0,           0],\n",
              "       ...,\n",
              "       [    0.99065,     0.99065,     0.99065, ...,           0,           0,           0],\n",
              "       [    0.97727,     0.97727,     0.96212, ...,           0,           0,           0],\n",
              "       [    0.97143,     0.97143,     0.97143, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
              "fitness: np.float64(0.48105760898542177)\n",
              "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
              "maps: array([    0.29136,      0.3961,     0.30709,     0.25317,     0.32307,      0.4532,     0.47711,     0.76134,     0.44507,     0.71898,     0.64125,     0.70496])\n",
              "names: {0: 'Ants', 1: 'Bees', 2: 'Beetles', 3: 'Caterpillars', 4: 'Earthworms', 5: 'Earwigs', 6: 'Grasshoppers', 7: 'Moths', 8: 'Slugs', 9: 'Snails', 10: 'Wasps', 11: 'Weevils'}\n",
              "nt_per_class: array([178, 110, 100, 139,  72, 104, 102, 101,  91, 107, 132, 105])\n",
              "nt_per_image: array([ 96,  99,  89,  77,  53,  91,  98, 100,  77,  99, 116, 104])\n",
              "results_dict: {'metrics/precision(B)': 0.8611971602538806, 'metrics/recall(B)': 0.7090349429324573, 'metrics/mAP50(B)': 0.7840338901432061, 'metrics/mAP50-95(B)': 0.48105760898542177, 'fitness': 0.48105760898542177}\n",
              "save_dir: PosixPath('/content/my_yolo_experiment/run_1')\n",
              "speed: {'preprocess': 0.13284366027017222, 'inference': 0.8200233506875221, 'loss': 0.000325760734147928, 'postprocess': 0.9267450840180577}\n",
              "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n",
              "task: 'detect'"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate best model\n",
        "best_model_path = \"/content/my_yolo_experiment/run_1/weights/best.pt\"\n",
        "best_model =YOLO(best_model_path)\n",
        "results =  best_model.val(data=\"data.yaml\",split=\"test\")\n",
        "\n",
        "# global summary metrics converting to float\n",
        "test_metrics = {\"precision_mean\": float(results.box.mp),\n",
        "    \"recall_mean\": float(results.box.mr) ,\n",
        "    \"mAP50_mean\":float(results.box.map50),\n",
        "    \"mAP50-95_mean\":float(results.box.map) ,\n",
        "    \"fitness\": float(results.fitness)}\n",
        "\n",
        "# per-class summary processing to save appropriately\n",
        "per_class_summary_raw =  results.summary()  # list of dicts\n",
        "per_class_summary =[]\n",
        "\n",
        "for entry in per_class_summary_raw:\n",
        "    clean_entry = {key:(float(val) if isinstance(val,(np.floating,np.integer)) else val)\n",
        "\n",
        "                   for key,val in entry.items()}\n",
        "    per_class_summary.append(clean_entry)\n",
        "\n",
        "# saving to json dump\n",
        "output_metrics_path = \"/content/test_metrics_full.json\"\n",
        "with open(output_metrics_path,\"w\") as f:\n",
        "    json.dump({\"global_metrics\": test_metrics,\n",
        "        \"per_class_metrics\":per_class_summary},\n",
        "              f,indent=4)\n",
        "\n",
        "print(\"Full test metrics saved to: \",output_metrics_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kaEtA_WWiou",
        "outputId": "3f77fbcc-0ff0-479e-aa0a-d9cabfb4c1fd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.226 ğŸš€ Python-3.12.12 torch-2.9.0+cu128 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "YOLOv12n summary (fused): 159 layers, 2,559,068 parameters, 0 gradients, 6.3 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1281.1Â±45.9 MB/s, size: 39.2 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/kaggle_data/test/labels.cache... 546 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 546/546 1.0Mit/s 0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 35/35 9.2it/s 3.8s\n",
            "                   all        546        689      0.824      0.756      0.795      0.481\n",
            "                  Ants         54         87       0.86      0.778      0.792      0.332\n",
            "                  Bees         40         44      0.834      0.909      0.877      0.476\n",
            "               Beetles         41         44      0.689      0.727      0.734      0.391\n",
            "          Caterpillars         46         93      0.722      0.503      0.671      0.365\n",
            "            Earthworms         27         40       0.71      0.575      0.575      0.276\n",
            "               Earwigs         59         73      0.769      0.644      0.722      0.406\n",
            "          Grasshoppers         38         55       0.86       0.56      0.639      0.331\n",
            "                 Moths         47         47      0.932      0.957      0.979      0.793\n",
            "                 Slugs         46         51      0.747       0.58      0.675      0.391\n",
            "                Snails         44         50      0.845       0.88      0.908      0.668\n",
            "                 Wasps         46         47      0.966      0.979      0.976      0.649\n",
            "               Weevils         58         58      0.956      0.983       0.99      0.699\n",
            "Speed: 1.1ms preprocess, 1.6ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/val2\u001b[0m\n",
            "Full test metrics saved to:  /content/test_metrics_full.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting metrics to a csv\n",
        "df = pd.DataFrame(per_class_summary)\n",
        "csv_path = \"/content/per_class_metrics.csv\"\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "#bar charts for mAP50 for each class\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.bar(df['Class'],df['mAP50'])\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"mAP@0.50\")\n",
        "plt.title(\"mAP@0.50 Score per Class\")\n",
        "plt.xticks(rotation=45,ha=\"right\")\n",
        "plt.tight_layout()\n",
        "\n",
        "chart_path = \"/content/mAP50_per_class.png\"\n",
        "plt.savefig(chart_path)\n",
        "plt.show()\n",
        "print(\"saved bar chart:\", chart_path)\n",
        "\n",
        "# Putting everything in one folder\n",
        "package_dir =\"/content/yolo_results_package\"\n",
        "\n",
        "if os.path.exists(package_dir):\n",
        "    shutil.rmtree(package_dir)\n",
        "os.makedirs(package_dir)\n",
        "\n",
        "# training results\n",
        "shutil.copytree(\"/content/my_yolo_experiment/run_1\", f\"{package_dir}/training_results\")\n",
        "\n",
        "# the best model\n",
        "shutil.copy(\"/content/my_yolo_experiment/run_1/weights/best.pt\", f\"{package_dir}/best_model.pt\")\n",
        "\n",
        "# test metrics in json format\n",
        "shutil.copy(output_metrics_path, f\"{package_dir}/test_metrics.json\")\n",
        "# the csv and chart\n",
        "shutil.copy(csv_path,f\"{package_dir}/per_class_metrics.csv\")\n",
        "shutil.copy(chart_path,f\"{package_dir}/mAP50_per_class.png\")\n",
        "\n",
        "# zip everything together to download it automatically after model has been trained\n",
        "zip_path = \"/content/yolo_results_package.zip\"\n",
        "shutil.make_archive(\"/content/yolo_results_package\",'zip',package_dir)\n",
        "files.download(zip_path)\n",
        "\n",
        "print(\"download started \\n\")\n",
        "print(\"Included:\\n- Training logs & charts\\n- best_model.pt\\n- test_metrics.json\\n- per_class_metrics.csv\\n- mAP50_per_class.png\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "id": "ieZ8B93Blwcx",
        "outputId": "ab1d9a5f-a1c6-4940-8323-0daf3f6c64bb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saved bar chart: /content/mAP50_per_class.png\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f4617cfd-0381-4462-8b24-ee803be8a5b7\", \"yolo_results_package.zip\", 21437870)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "download started \n",
            "\n",
            "Included:\n",
            "- Training logs & charts\n",
            "- best_model.pt\n",
            "- test_metrics.json\n",
            "- per_class_metrics.csv\n",
            "- mAP50_per_class.png\n"
          ]
        }
      ]
    }
  ]
}